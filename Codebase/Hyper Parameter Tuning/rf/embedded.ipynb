{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849983c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"C:/Users/H A R I H A R A N/Desktop/sem 8/Heart Disease/heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66056592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.52459016393442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "new = df[['age','sex','cp','trestbps','restecg','exang','slope','ca','thal','target']]\n",
    "\n",
    "Y = new['target']\n",
    "X = new.drop(['target'], axis = 1)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "rf_Model = RandomForestClassifier() \n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)\n",
    "X = new.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed389f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1650 fits failed out of a total of 4950.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1650 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.814\n",
      " 0.83066667 0.81816667 0.83883333 0.83466667 0.8265     0.84316667\n",
      " 0.82633333 0.83466667 0.8345            nan        nan        nan\n",
      "        nan        nan 0.82233333 0.83883333 0.83066667 0.8265\n",
      " 0.82666667 0.82633333 0.82233333 0.839      0.83066667 0.8305\n",
      "        nan        nan        nan        nan        nan 0.814\n",
      " 0.81416667 0.81       0.83483333 0.8305     0.82233333 0.814\n",
      " 0.83883333 0.82233333 0.8265            nan        nan        nan\n",
      "        nan        nan 0.83483333 0.83033333 0.83883333 0.8305\n",
      " 0.8305     0.83883333 0.82633333 0.82633333 0.83466667 0.83033333\n",
      "        nan        nan        nan        nan        nan 0.839\n",
      " 0.83483333 0.82233333 0.82633333 0.83083333 0.83483333 0.8305\n",
      " 0.847      0.8305     0.8265            nan        nan        nan\n",
      "        nan        nan 0.82666667 0.83066667 0.82233333 0.81833333\n",
      " 0.83483333 0.80983333 0.82633333 0.8265     0.839      0.82233333\n",
      "        nan        nan        nan        nan        nan 0.82616667\n",
      " 0.82633333 0.81816667 0.83883333 0.8305     0.84716667 0.82633333\n",
      " 0.8305     0.83066667 0.82633333        nan        nan        nan\n",
      "        nan        nan 0.8305     0.8305     0.83883333 0.82633333\n",
      " 0.84283333 0.83033333 0.84316667 0.82666667 0.83866667 0.83483333\n",
      "        nan        nan        nan        nan        nan 0.8265\n",
      " 0.802      0.843      0.8305     0.83466667 0.82233333 0.83483333\n",
      " 0.83483333 0.83066667 0.82216667        nan        nan        nan\n",
      "        nan        nan 0.818      0.8345     0.8305     0.82233333\n",
      " 0.83033333 0.83883333 0.82633333 0.8265     0.83866667 0.8305\n",
      "        nan        nan        nan        nan        nan 0.83066667\n",
      " 0.83483333 0.8265     0.83466667 0.8265     0.83466667 0.8265\n",
      " 0.843      0.83483333 0.83066667        nan        nan        nan\n",
      "        nan        nan 0.81433333 0.83466667 0.82233333 0.83066667\n",
      " 0.83466667 0.835      0.83066667 0.82233333 0.843      0.83483333\n",
      "        nan        nan        nan        nan        nan 0.83066667\n",
      " 0.82633333 0.83066667 0.82216667 0.8305     0.818      0.83883333\n",
      " 0.8305     0.83066667 0.8305            nan        nan        nan\n",
      "        nan        nan 0.84283333 0.83066667 0.83466667 0.83083333\n",
      " 0.83483333 0.83066667 0.83883333 0.83066667 0.839      0.83066667\n",
      "        nan        nan        nan        nan        nan 0.8225\n",
      " 0.82666667 0.8265     0.83066667 0.83066667 0.82233333 0.8265\n",
      " 0.82233333 0.83066667 0.83466667        nan        nan        nan\n",
      "        nan        nan 0.8305     0.83866667 0.83883333 0.8305\n",
      " 0.8345     0.82633333 0.83483333 0.83466667 0.8305     0.83883333\n",
      "        nan        nan        nan        nan        nan 0.83033333\n",
      " 0.8265     0.83066667 0.839      0.82633333 0.83066667 0.8265\n",
      " 0.83066667 0.84283333 0.83466667        nan        nan        nan\n",
      "        nan        nan 0.81833333 0.82633333 0.82233333 0.8265\n",
      " 0.8305     0.83466667 0.8225     0.81       0.83483333 0.82233333\n",
      "        nan        nan        nan        nan        nan 0.814\n",
      " 0.83483333 0.8305     0.83883333 0.83466667 0.83483333 0.83466667\n",
      " 0.8225     0.83466667 0.8305            nan        nan        nan\n",
      "        nan        nan 0.83066667 0.83866667 0.82666667 0.843\n",
      " 0.83483333 0.82233333 0.83483333 0.83466667 0.8345     0.8265\n",
      "        nan        nan        nan        nan        nan 0.82216667\n",
      " 0.82266667 0.8305     0.82233333 0.8265     0.8185     0.818\n",
      " 0.83066667 0.83466667 0.843             nan        nan        nan\n",
      "        nan        nan 0.82633333 0.83883333 0.82633333 0.8305\n",
      " 0.83883333 0.83066667 0.83883333 0.82633333 0.83466667 0.83466667\n",
      "        nan        nan        nan        nan        nan 0.8265\n",
      " 0.839      0.83483333 0.83916667 0.83883333 0.84283333 0.8305\n",
      " 0.83483333 0.8345     0.8265            nan        nan        nan\n",
      "        nan        nan 0.83066667 0.835      0.84333333 0.83066667\n",
      " 0.83066667 0.83083333 0.83483333 0.814      0.8305     0.843\n",
      "        nan        nan        nan        nan        nan 0.83033333\n",
      " 0.8345     0.83466667 0.83866667 0.8305     0.83466667 0.83883333\n",
      " 0.8305     0.843      0.83483333        nan        nan        nan\n",
      "        nan        nan 0.8225     0.83483333 0.83466667 0.84283333\n",
      " 0.82666667 0.8265     0.8265     0.83066667 0.839      0.8265\n",
      "        nan        nan        nan        nan        nan 0.81816667\n",
      " 0.81833333 0.843      0.8305     0.81816667 0.82616667 0.8305\n",
      " 0.81833333 0.839      0.83466667        nan        nan        nan\n",
      "        nan        nan 0.82666667 0.843      0.83466667 0.8305\n",
      " 0.83066667 0.83033333 0.83066667 0.8305     0.83466667 0.83883333\n",
      "        nan        nan        nan        nan        nan 0.85133333\n",
      " 0.83066667 0.83483333 0.843      0.83066667 0.81416667 0.83483333\n",
      " 0.83483333 0.83483333 0.843             nan        nan        nan\n",
      "        nan        nan 0.8185     0.83066667 0.8265     0.83066667\n",
      " 0.83466667 0.82233333 0.82633333 0.82633333 0.8305     0.82666667\n",
      "        nan        nan        nan        nan        nan 0.82216667\n",
      " 0.82666667 0.8345     0.8305     0.84283333 0.843      0.83866667\n",
      " 0.84283333 0.83466667 0.8305            nan        nan        nan\n",
      "        nan        nan 0.83066667 0.83466667 0.83483333 0.82233333\n",
      " 0.83883333 0.83883333 0.83083333 0.8305     0.8265     0.83466667\n",
      "        nan        nan        nan        nan        nan 0.839\n",
      " 0.83466667 0.82216667 0.82216667 0.83483333 0.81383333 0.8265\n",
      " 0.82233333 0.83066667 0.843     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=890, max_features='sqrt', min_samples_leaf=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRID SEARCH CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_Model = RandomForestClassifier() \n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "forest_params = [{'max_depth': [800,810,820,830,840,850,860,870,880,890,900],\n",
    "                  'max_features': ['sqrt'],\n",
    "                  'criterion' : ['gini'] ,\n",
    "                  'min_samples_leaf': [1,2,3],\n",
    "                  'min_samples_split': [1,2,3],\n",
    "                  'n_estimators':[100,200,300,400,500]}]\n",
    "clf = GridSearchCV(model, forest_params, cv = 10, scoring='accuracy')\n",
    "best_clf = clf.fit(x_train,y_train)\n",
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edd0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.1639344262295\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "rf_Model = RandomForestClassifier(max_depth=890, max_features='sqrt', min_samples_leaf=2)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9557738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=650, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=660, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=620, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=610, max_features=sqrt, min_samples_leaf=3, min_samples_split=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "70 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.83066667        nan        nan\n",
      "        nan 0.82233333        nan 0.8305    ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=620, max_features='sqrt', min_samples_leaf=3,\n",
       "                       min_samples_split=4, n_estimators=400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOMIZED SEARCH CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "forest_params = [{'max_depth': [600,610,620,630,640,650,660,670,680,690,700],\n",
    "                  'max_features': ['sqrt','log2'],\n",
    "                  'criterion' : ['gini'] ,\n",
    "                  'min_samples_leaf': [1,2,3],\n",
    "                  'min_samples_split': [1,2,4],\n",
    "                  'n_estimators':[100,200,300,400]}]\n",
    "rf_RandomGrid = RandomizedSearchCV(estimator = rf_Model, param_distributions = forest_params, cv = 10, verbose=2, scoring = 'accuracy')\n",
    "best_clf = rf_RandomGrid.fit(x_train,y_train)\n",
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aaa8016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.80327868852459\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "rf_Model = RandomForestClassifier(max_depth=620, max_features='sqrt', min_samples_leaf=3,\n",
    "                       min_samples_split=4, n_estimators=400)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8a353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 610), ('max_features', 'sqrt'), ('n_estimators', 100)])\n",
      "Accuracy:0.7975823045267489\n"
     ]
    }
   ],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "import numpy as np\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': np.arange(100,1100),\n",
    "    \"max_features\":['log2','sqrt'],\n",
    "    'max_depth': np.arange(600,1000),\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=135)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, n_jobs=-1,scoring='accuracy')\n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "Bayes.fit(x_train, y_train)\n",
    "print(Bayes.best_params_)\n",
    "bclf = Bayes.best_estimator_\n",
    "print(\"Accuracy:\"+ str(Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "541be395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.44262295081968\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 169)\n",
    "rf_Model = RandomForestClassifier(max_depth=610, max_features='sqrt',criterion = 'entropy', n_estimators=100)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5ca77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62539fd9087479188fec54a4c24b4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8140306122448979\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=898, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=817)\n",
      "\n",
      "The optimized pipeline was not improved after evaluating 5 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['gini',\n",
       "                                                                                      'entropy'],\n",
       "                                                                        'max_depth': array([600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
       "       613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625,\n",
       "       626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638,\n",
       "       639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651,\n",
       "       652, 653, 654, 655, 656, 6...\n",
       "       1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056,\n",
       "       1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "       1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "       1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089,\n",
       "       1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099])}},\n",
       "               early_stop=5, generations=10, offspring_size=5,\n",
       "               population_size=10, scoring='accuracy', verbosity=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "# Define the hyperparameter configuration space\n",
    "parameters = {\n",
    "        'n_estimators': np.arange(100,1100),\n",
    "    \"max_features\":['log2','sqrt'],\n",
    "    'max_depth': np.arange(600,1000),\n",
    "    \"min_samples_split\":range(2,5),\n",
    "    \"min_samples_leaf\":range(1,4),\n",
    "    \"criterion\":['gini','entropy']\n",
    "             }\n",
    "# Set the hyperparameters of GA                 \n",
    "ga2 = TPOTClassifier(generations= 10, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.ensemble.RandomForestClassifier': parameters}, \n",
    "                                 cv = 5, scoring = 'accuracy')\n",
    "ga2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143f4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.1639344262295\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 65)\n",
    "rf_Model = RandomForestClassifier(max_depth=898, max_features='sqrt',criterion = 'gini', n_estimators=817,min_samples_split=4)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4358f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
