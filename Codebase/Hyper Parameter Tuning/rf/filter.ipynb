{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4adad0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"C:/Users/H A R I H A R A N/Desktop/sem 8/Heart Disease/heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b31285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "new = df[['thalach', 'oldpeak', 'ca', 'cp', 'exang', 'chol', 'age', 'trestbps', 'slope', 'sex','target']]\n",
    "\n",
    "Y = new['target']\n",
    "X = new.drop(['target'], axis = 1)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194d0a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.44262295081968\n"
     ]
    }
   ],
   "source": [
    "rf_Model = RandomForestClassifier() \n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)\n",
    "X = new.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74089d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1650 fits failed out of a total of 4950.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1650 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.801\n",
      " 0.78916667 0.78866667 0.80933333 0.81766667 0.79716667 0.785\n",
      " 0.80133333 0.79316667 0.79733333        nan        nan        nan\n",
      "        nan        nan 0.8015     0.80983333 0.814      0.78916667\n",
      " 0.78916667 0.793      0.80133333 0.8055     0.79316667 0.80166667\n",
      "        nan        nan        nan        nan        nan 0.7975\n",
      " 0.80166667 0.80133333 0.8055     0.7975     0.80166667 0.79733333\n",
      " 0.79316667 0.80533333 0.79716667        nan        nan        nan\n",
      "        nan        nan 0.8015     0.79333333 0.8055     0.785\n",
      " 0.80116667 0.79316667 0.80966667 0.80566667 0.80966667 0.8055\n",
      "        nan        nan        nan        nan        nan 0.79316667\n",
      " 0.78916667 0.7975     0.8055     0.8015     0.818      0.80966667\n",
      " 0.80133333 0.8095     0.80966667        nan        nan        nan\n",
      "        nan        nan 0.78466667 0.79733333 0.8055     0.79733333\n",
      " 0.79733333 0.79733333 0.797      0.79716667 0.79316667 0.80133333\n",
      "        nan        nan        nan        nan        nan 0.78066667\n",
      " 0.79733333 0.8055     0.80116667 0.793      0.78933333 0.79716667\n",
      " 0.80133333 0.79316667 0.79333333        nan        nan        nan\n",
      "        nan        nan 0.814      0.82216667 0.80166667 0.80966667\n",
      " 0.8015     0.80533333 0.80566667 0.8055     0.8015     0.7975\n",
      "        nan        nan        nan        nan        nan 0.793\n",
      " 0.80966667 0.80583333 0.80133333 0.79716667 0.80516667 0.79733333\n",
      " 0.8015     0.79716667 0.8015            nan        nan        nan\n",
      "        nan        nan 0.80983333 0.77666667 0.78916667 0.79316667\n",
      " 0.789      0.80966667 0.8015     0.80166667 0.79716667 0.80116667\n",
      "        nan        nan        nan        nan        nan 0.78066667\n",
      " 0.80966667 0.80983333 0.8095     0.78916667 0.80566667 0.80133333\n",
      " 0.79733333 0.8015     0.8055            nan        nan        nan\n",
      "        nan        nan 0.80983333 0.81383333 0.8015     0.80133333\n",
      " 0.79716667 0.789      0.79316667 0.79333333 0.8015     0.8055\n",
      "        nan        nan        nan        nan        nan 0.79283333\n",
      " 0.80116667 0.78466667 0.7805     0.80533333 0.79333333 0.797\n",
      " 0.80966667 0.79716667 0.80533333        nan        nan        nan\n",
      "        nan        nan 0.8095     0.80566667 0.79716667 0.79716667\n",
      " 0.78916667 0.793      0.781      0.789      0.79716667 0.80566667\n",
      "        nan        nan        nan        nan        nan 0.78916667\n",
      " 0.8015     0.79716667 0.79733333 0.79733333 0.79733333 0.7975\n",
      " 0.79733333 0.79733333 0.79733333        nan        nan        nan\n",
      "        nan        nan 0.79733333 0.80133333 0.8055     0.79316667\n",
      " 0.80966667 0.78883333 0.79716667 0.8055     0.793      0.79733333\n",
      "        nan        nan        nan        nan        nan 0.79716667\n",
      " 0.80166667 0.80566667 0.80966667 0.8055     0.8015     0.80983333\n",
      " 0.79316667 0.79733333 0.79316667        nan        nan        nan\n",
      "        nan        nan 0.77683333 0.78916667 0.80533333 0.80533333\n",
      " 0.79716667 0.80133333 0.8055     0.78083333 0.79316667 0.79333333\n",
      "        nan        nan        nan        nan        nan 0.80566667\n",
      " 0.78066667 0.81783333 0.80533333 0.79716667 0.80133333 0.81816667\n",
      " 0.80133333 0.793      0.79733333        nan        nan        nan\n",
      "        nan        nan 0.79333333 0.7975     0.79733333 0.8055\n",
      " 0.8015     0.8055     0.80116667 0.8015     0.81       0.80166667\n",
      "        nan        nan        nan        nan        nan 0.79316667\n",
      " 0.8015     0.79733333 0.80133333 0.79716667 0.78933333 0.79716667\n",
      " 0.8015     0.79316667 0.79716667        nan        nan        nan\n",
      "        nan        nan 0.80133333 0.79316667 0.81783333 0.79316667\n",
      " 0.79716667 0.79283333 0.80566667 0.8055     0.79316667 0.78883333\n",
      "        nan        nan        nan        nan        nan 0.80966667\n",
      " 0.8095     0.79733333 0.80566667 0.79333333 0.7975     0.80583333\n",
      " 0.79283333 0.79333333 0.8015            nan        nan        nan\n",
      "        nan        nan 0.79333333 0.7975     0.80566667 0.80133333\n",
      " 0.80533333 0.8055     0.79733333 0.80966667 0.80566667 0.80116667\n",
      "        nan        nan        nan        nan        nan 0.8015\n",
      " 0.80133333 0.79733333 0.80533333 0.80933333 0.80983333 0.8055\n",
      " 0.78483333 0.789      0.80516667        nan        nan        nan\n",
      "        nan        nan 0.79716667 0.793      0.80966667 0.81366667\n",
      " 0.7975     0.80966667 0.8095     0.79733333 0.80566667 0.80966667\n",
      "        nan        nan        nan        nan        nan 0.79316667\n",
      " 0.80133333 0.80116667 0.79316667 0.79716667 0.80133333 0.80966667\n",
      " 0.80966667 0.8055     0.79733333        nan        nan        nan\n",
      "        nan        nan 0.78083333 0.80933333 0.79716667 0.79716667\n",
      " 0.79716667 0.793      0.79716667 0.8095     0.80966667 0.80133333\n",
      "        nan        nan        nan        nan        nan 0.79733333\n",
      " 0.8055     0.8015     0.80133333 0.8015     0.79716667 0.80116667\n",
      " 0.8015     0.8015     0.80566667        nan        nan        nan\n",
      "        nan        nan 0.79316667 0.79316667 0.79716667 0.79316667\n",
      " 0.79716667 0.8015     0.8055     0.79766667 0.79316667 0.79716667\n",
      "        nan        nan        nan        nan        nan 0.78466667\n",
      " 0.80133333 0.814      0.8135     0.78866667 0.793      0.8015\n",
      " 0.8015     0.79316667 0.81383333        nan        nan        nan\n",
      "        nan        nan 0.78916667 0.80533333 0.81383333 0.8055\n",
      " 0.8055     0.8135     0.80533333 0.81383333 0.80166667 0.7975\n",
      "        nan        nan        nan        nan        nan 0.8055\n",
      " 0.79716667 0.7975     0.80116667 0.79316667 0.785      0.79333333\n",
      " 0.80133333 0.8055     0.79733333]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=820, max_features='sqrt', min_samples_leaf=2,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_Model = RandomForestClassifier() \n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "forest_params = [{'max_depth': [800,810,820,830,840,850,860,870,880,890,900],\n",
    "                  'max_features': ['sqrt'],\n",
    "                  'criterion' : ['gini'] ,\n",
    "                  'min_samples_leaf': [1,2,3],\n",
    "                  'min_samples_split': [1,2,3],\n",
    "                  'n_estimators':[100,200,300,400,500]}]\n",
    "clf = GridSearchCV(model, forest_params, cv = 10, scoring='accuracy')\n",
    "best_clf = clf.fit(x_train,y_train)\n",
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6d03ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.08196721311475\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "rf_Model = RandomForestClassifier(max_depth=820, max_features='sqrt', min_samples_leaf=2,\n",
    "                       n_estimators=200)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4abf9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=690, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=700, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=600, max_features=log2, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=630, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=680, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=640, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\H A R I H A R A N\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.80566667 0.80533333 0.8095            nan 0.80983333        nan\n",
      " 0.79333333 0.79716667 0.79716667 0.80566667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=700, max_features='sqrt', min_samples_leaf=2,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOMIZED SEARCH CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 135)\n",
    "forest_params = [{'max_depth': [600,610,620,630,640,650,660,670,680,690,700],\n",
    "                  'max_features': ['sqrt','log2'],\n",
    "                  'criterion' : ['gini'] ,\n",
    "                  'min_samples_leaf': [1,2,3],\n",
    "                  'min_samples_split': [1,2,4],\n",
    "                  'n_estimators':[100,200,300,400]}]\n",
    "rf_RandomGrid = RandomizedSearchCV(estimator = rf_Model, param_distributions = forest_params, cv = 10, verbose=2, scoring = 'accuracy')\n",
    "best_clf = rf_RandomGrid.fit(x_train,y_train)\n",
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b711a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.44262295081968\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 65)\n",
    "rf_Model = RandomForestClassifier(max_depth=700, max_features='sqrt', min_samples_leaf=2,\n",
    "                       n_estimators=200)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4e4fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No clients found\nStart a client and point it to the scheduler address\n  from distributed import Client\n  client = Client('ip-addr-of-scheduler:8786')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m hyper \u001b[38;5;241m=\u001b[39m HyperbandSearchCV(clf, rf_params)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mhyper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(hyper\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(hyper\u001b[38;5;241m.\u001b[39mbest_score_))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask_ml\\model_selection\\_incremental.py:725\u001b[0m, in \u001b[0;36mBaseIncrementalSearchCV.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the best parameters for a particular model.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;124;03m        Additional partial fit keyword arguments for the estimator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 725\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client\u001b[38;5;241m.\u001b[39masynchronous:\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39msync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py:5147\u001b[0m, in \u001b[0;36mdefault_client\u001b[1;34m(c)\u001b[0m\n\u001b[0;32m   5145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c\n\u001b[0;32m   5146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   5148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo clients found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart a client and point it to the scheduler address\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  from distributed import Client\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  client = Client(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mip-addr-of-scheduler:8786\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5152\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: No clients found\nStart a client and point it to the scheduler address\n  from distributed import Client\n  client = Client('ip-addr-of-scheduler:8786')\n"
     ]
    }
   ],
   "source": [
    "# Hyperband   https://neptune.ai/blog/hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms\n",
    "#  https://analyticsindiamag.com/speed-up-hyperparameter-tuning-in-deep-learning-with-keras-hyperband-tuner/\n",
    "\n",
    "#from scikit-hyperband import HyperbandSearchCV\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': [100,200,300,400],\n",
    "    \"max_features\": ['sqrt','log2'],\n",
    "    'max_depth': [600,610,620,630,640,650,660,670,680,690,700],\n",
    "    \"min_samples_split\": [1,2,3,4,5],\n",
    "    \"min_samples_leaf\": [1,2,3,4,5],\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "hyper = HyperbandSearchCV(clf, rf_params)\n",
    "hyper.fit(x_train,y_train)\n",
    "print(hyper.best_params_)\n",
    "print(\"Accuracy:\"+ str(hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c63def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/thuijskens/scikit-hyperband.git 2>/dev/null 1>/dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4fd7dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 759), ('max_features', 'log2'), ('n_estimators', 976)])\n",
      "Accuracy:0.7852366255144032\n"
     ]
    }
   ],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': np.arange(100,1100),\n",
    "    \"max_features\":['log2','sqrt'],\n",
    "    'max_depth': np.arange(600,1000),\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=135)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, n_jobs=-1,scoring='accuracy')\n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "Bayes.fit(x_train, y_train)\n",
    "print(Bayes.best_params_)\n",
    "bclf = Bayes.best_estimator_\n",
    "print(\"Accuracy:\"+ str(Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ee9df2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.08196721311475\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 65)\n",
    "rf_Model = RandomForestClassifier(max_depth=759, max_features='log2', min_samples_leaf=2,criterion ='entropy',\n",
    "                       n_estimators=200)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8be3f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7930272108843537\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=959, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=486)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7930272108843537\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=959, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=486)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7930272108843537\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=959, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=486)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7930272108843537\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=959, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=486)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7930272108843537\tRandomForestClassifier(CombineDFs(input_matrix, input_matrix), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=959, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=486)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7972789115646258\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=953, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=1057)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7972789115646258\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=953, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=1057)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7972789115646258\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=953, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=1057)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7972789115646258\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=953, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=1057)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7972789115646258\tRandomForestClassifier(input_matrix, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=953, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=1, RandomForestClassifier__min_samples_split=2, RandomForestClassifier__n_estimators=1057)\n",
      "\n",
      "-2\t0.8098639455782314\tRandomForestClassifier(RandomForestClassifier(input_matrix, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_depth=996, RandomForestClassifier__max_features=sqrt, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=500), RandomForestClassifier__criterion=gini, RandomForestClassifier__max_depth=693, RandomForestClassifier__max_features=log2, RandomForestClassifier__min_samples_leaf=2, RandomForestClassifier__min_samples_split=3, RandomForestClassifier__n_estimators=952)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['gini',\n",
       "                                                                                      'entropy'],\n",
       "                                                                        'max_depth': array([600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
       "       613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625,\n",
       "       626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638,\n",
       "       639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651,\n",
       "       652, 653, 654, 655, 656, 6...\n",
       "       1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056,\n",
       "       1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "       1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "       1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089,\n",
       "       1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099])}},\n",
       "               early_stop=5, generations=10, offspring_size=5,\n",
       "               population_size=10, scoring='accuracy', verbosity=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "# Define the hyperparameter configuration space\n",
    "parameters = {\n",
    "        'n_estimators': np.arange(100,1100),\n",
    "    \"max_features\":['log2','sqrt'],\n",
    "    'max_depth': np.arange(600,1000),\n",
    "    \"min_samples_split\":range(2,5),\n",
    "    \"min_samples_leaf\":range(1,4),\n",
    "    \"criterion\":['gini','entropy']\n",
    "             }\n",
    "# Set the hyperparameters of GA                 \n",
    "ga2 = TPOTClassifier(generations= 10, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.ensemble.RandomForestClassifier': parameters}, \n",
    "                                 cv = 5, scoring = 'accuracy')\n",
    "ga2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0aa3232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.44262295081968\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.20, random_state = 65)\n",
    "rf_Model = RandomForestClassifier(max_depth=996, max_features='log2', min_samples_leaf=2,criterion ='gini',min_samples_split=3,\n",
    "                       n_estimators=952)\n",
    "model = rf_Model.fit(x_train,y_train)\n",
    "print (model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd57737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
